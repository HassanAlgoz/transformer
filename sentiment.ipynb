{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9c13ecf-9098-4898-a0ef-63436ee50bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (/home/hgoz/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "Found cached dataset tweet_eval (/home/hgoz/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_train = load_dataset(\"tweet_eval\", \"sentiment\", split=\"train[:50]\")\n",
    "dataset_test = load_dataset(\"tweet_eval\", \"sentiment\", split=\"test[:5]\")\n",
    "dataset_train.set_format(type=\"torch\", columns=[\"text\", \"label\"])\n",
    "dataset_test.set_format(type=\"torch\", columns=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d8d01c2-d72f-43dd-a22a-bf08c23405e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ec6c560-a273-4145-b408-577d73c37b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "embeddings_kv = KeyedVectors.load_word2vec_format('./data/glove.6B.300d.w2v.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79c86674-5494-4e8a-9b18-8e824cea4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.tensor(embeddings_kv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f68c72e0-d0f0-46ea-950a-f0af5599bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = {\n",
    "    'none': 0,\n",
    "    'against': 1,\n",
    "    'favor': 2,\n",
    "}\n",
    "idx_to_label = {\n",
    "    0: 'none',\n",
    "    1: 'against',\n",
    "    2: 'favor',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2639d998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 10])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 10, 28)\n",
    "y = torch.randn(3, 28, 10)\n",
    "z = torch.bmm(x, y)\n",
    "z.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d616e808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 10])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c33efae8-aba1-40c9-8db3-bcfb98961cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class AttentionHead(nn.Module): \n",
    "    \n",
    "    def __init__(self, d_model):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        \n",
    "        # Attention layer\n",
    "        self.w_q = nn.Linear(embeddings.shape[1], d_model)\n",
    "        self.w_k = nn.Linear(embeddings.shape[1], d_model)\n",
    "        self.w_v = nn.Linear(embeddings.shape[1], d_model)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # Feed Forward layer\n",
    "        self.fc1 = nn.Linear(d_model, d_model*4) # Dense layer with 4*d_model units \n",
    "        self.fc2 = nn.Linear(d_model*4, d_model) # Output dense layer of d_model units\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # X shape: (batch_size, seq_len, d_model)  \n",
    "       \n",
    "        # Apply linear transformations\n",
    "        q = self.w_q(X)\n",
    "        k = self.w_k(X)\n",
    "        v = self.w_v(X)\n",
    "        \n",
    "        # Calculate attention weights\n",
    "        attention_scores = torch.einsum(\"bsa,bsb->abs\", q, k)  # Get score matrix\n",
    "        attention_weights = self.softmax(attention_scores) \n",
    "        \n",
    "        # Weighted sum of values  \n",
    "        context = torch.einsum(\"abs,abv->bsv\", attention_weights, v)\n",
    "        \n",
    "        # Apply feed forward layer\n",
    "        output = self.fc2(self.relu(self.fc1(context)))\n",
    "        \n",
    "        return output\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, normalized_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        \n",
    "    def forward(self, x):    \n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + 1e-5)  + self.beta\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, sequence_length, heads, num_layers, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=True)\n",
    "\n",
    "        self.q = nn.Linear(embeddings.shape[1], embeddings.shape[1])\n",
    "        self.k = nn.Linear(embeddings.shape[1], embeddings.shape[1])\n",
    "        self.v = nn.Linear(embeddings.shape[1], embeddings.shape[1])\n",
    "        self.ln1 = LayerNorm(embeddings.shape[1])\n",
    "\n",
    "        self.ff = nn.Linear(embeddings.shape[1], embeddings.shape[1])\n",
    "        self.ln2 = LayerNorm(embeddings.shape[1])\n",
    "\n",
    "        self.fc = nn.Linear(sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch_size, seq_len, _ = x.size()\n",
    "        x = self.embedding(x)\n",
    "        # .view(batch_size, -1, heads, embed_dim//heads).transpose(1,2)   \n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "        att = F.softmax((q * k.T) / math.sqrt(embeddings.shape[1]), dim=1) * v \n",
    "        x =  self.ln1(x + att)\n",
    "        x = self.ln2(x + self.ff(x))\n",
    "        y_pred = F.log_softmax(self.fc(x), dim=1)\n",
    "        return y_pred[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8506bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# class PositionalEncoding(nn.Module):\n",
    "    \n",
    "#     def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "#         super().__init__()\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "#         # Compute the positional encodings once in advance\n",
    "#         pe = torch.zeros(max_len, d_model)\n",
    "#         position = torch.arange(0, max_len).unsqueeze(1)\n",
    "#         div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "#                              -(math.log(10000.0) / d_model))\n",
    "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
    "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
    "#         pe = pe.unsqueeze(0)\n",
    "#         self.register_buffer('pe', pe)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = x + self.pe[:, :x.size(1)]        \n",
    "#         return self.dropout(x)\n",
    "\n",
    "# class TransformerModel(nn.Module):\n",
    "#     def __init__(self, ntoken, d_model, nhead, d_hid, nlayers, dropout=0.5):\n",
    "#         super().__init__()\n",
    "#         self.d_model = d_model\n",
    "#         encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "#         self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "#         self.embedding = nn.Embedding(ntoken, d_model)\n",
    "#         self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "#         self.out = nn.Linear(d_model, ntoken)\n",
    "    \n",
    "#     def forward(self, src):\n",
    "#         src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "#         src = self.pos_encoder(src)\n",
    "#         output = self.transformer_encoder(src)\n",
    "#         output = self.out(output)\n",
    "#         return output\n",
    "\n",
    "# # m = TransformerModel(embeddings.shape[0], embeddings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2531a7bc-7422-44fc-b72c-3a854486fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length: 28\n",
      "num_texts: 50\n",
      "total_length: 957\n",
      "avg text length: 19\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "length_counts = 0\n",
    "num_texts = len(dataset_train['text'])\n",
    "for text in dataset_train['text']:\n",
    "    words = text.split(' ')\n",
    "    length_counts += len(words)\n",
    "    if len(words) > max_length:\n",
    "        max_length = len(words)\n",
    "\n",
    "print('max_length:', max_length)\n",
    "print('num_texts:', num_texts)\n",
    "print('total_length:', length_counts)\n",
    "avg_text_length = length_counts // num_texts\n",
    "print('avg text length:', avg_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d57b5fc5-abef-4b7b-b3dd-8694a05acd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs = []\n",
    "for text in dataset_train['text']:\n",
    "    l = []\n",
    "    for w in text.split(' '):\n",
    "        if w in embeddings_kv:\n",
    "            l.append(embeddings_kv.key_to_index[w])\n",
    "    # PAD using dots\n",
    "    for i in range(max_length - len(l)):\n",
    "        l.append(embeddings_kv.key_to_index['.'])\n",
    "    train_inputs.append(l)\n",
    "torch.tensor(train_inputs[:3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14278be0-537a-4b4b-926c-81620c54534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = []\n",
    "for text in dataset_test['text']:\n",
    "    l = []\n",
    "    for w in text.split(' '):\n",
    "        if w in embeddings_kv:\n",
    "            l.append(embeddings_kv.key_to_index[w])\n",
    "    # PAD using dots\n",
    "    for i in range(max_length - len(l)):\n",
    "        l.append(embeddings_kv.key_to_index['.'])\n",
    "    test_inputs.append(l)\n",
    "torch.tensor(test_inputs[:3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f15ebe66-2b1e-4941-b451-2247e3eeb0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 1, 1, 2, 0, 1, 1, 2, 2, 0, 1, 1, 2, 1, 1,\n",
       "        1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 0, 2, 1, 1, 2, 2,\n",
       "        1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d174ab89-2b33-4397-86c5-6719aed467fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n",
    "from torch.utils import data\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "device = torch_directml.device()\n",
    "\n",
    "model = NeuralNetwork(max_length, 20, 2, 3).to(device)\n",
    "# model.load_state_dict(torch.load('model.pt'))\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_X = torch.tensor(train_inputs).to(device)\n",
    "train_y = dataset_train['label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acac24b5-360d-4b26-9699-3cfa504dea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15999a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 28])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc4b5377-223f-4320-86c1-7be50557c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21024/1601400042.py:40: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  att = F.softmax((q * k.T) / math.sqrt(embeddings.shape[1]), dim=1) * v\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (28) must match the size of tensor b (50) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m     \u001b[39m# Forward pass: compute predicted y by passing x to the model.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     output \u001b[39m=\u001b[39m model(train_X)\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Calculate the loss\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(output, train_y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[76], line 40\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk(x)\n\u001b[1;32m     39\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv(x)\n\u001b[0;32m---> 40\u001b[0m att \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax((q \u001b[39m*\u001b[39;49m k\u001b[39m.\u001b[39;49mT) \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(embeddings\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m v \n\u001b[1;32m     41\u001b[0m x \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln1(x \u001b[39m+\u001b[39m att)\n\u001b[1;32m     42\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mff(x))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (50) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    output = model(train_X)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = loss_fn(output, train_y)\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the Tensors it will update (which are the learnable weights\n",
    "    # of the model)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record loss and epoch values\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        train_losses.append(loss.item())\n",
    "        epochs.append(epoch)\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(torch.arange(0, len(epochs), 1), train_losses, 1)\n",
    "plt.title('Training Loss over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "print(train_losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66a9921a-8fd4-4abb-bccc-90b13a034d29",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (140x300 and 28x300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     pred \u001b[39m=\u001b[39m model(test_X)\n\u001b[1;32m      7\u001b[0m     pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(pred, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m num_correct \u001b[39m=\u001b[39m (pred \u001b[39m==\u001b[39m test_y)\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[64], line 37\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     36\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(x)\n\u001b[0;32m---> 37\u001b[0m     q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq(x)\n\u001b[1;32m     38\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk(x)\n\u001b[1;32m     39\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (140x300 and 28x300)"
     ]
    }
   ],
   "source": [
    "test_X = torch.tensor(test_inputs).to(device)\n",
    "test_y = dataset_test['label'].to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(test_X)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "num_correct = (pred == test_y).sum()\n",
    "accuracy = num_correct / len(test_y)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"The accuracy of the testing set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2607ad38-2f9a-49b9-84aa-bbcaaf15fa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGAINST       what do these naked have to do with not even like\n",
      "AGAINST       had a blue penis while was with\n",
      "AGAINST       but think the victims are going to be\n",
      "FAVOR       think may be finally in with the in crowd\n",
      "NONE       and now and are running out of\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(test_inputs, dataset_test['label']):\n",
    "    text = ' '.join([embeddings_kv.index_to_key[i] for i in x if i != 2])\n",
    "    print(idx_to_label[y.item()].upper(), ' ' * 5, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
